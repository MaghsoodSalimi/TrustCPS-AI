<!--
<meta charset="utf-8">
<meta http-equiv="refresh" content="0; URL=https://HCC2023.github.io/{{ https://zmoez.github.io/HCC2023.github.io/ }}">
<meta http-equiv="refresh" content="0; URL=https://HCC2023.github.io">
-->


<!--
<img src="./HCC2023-2.png" align="left" height="400" width="1024" >

<img src="./HCC2023-3.png" align="left" height="400" width="1024" >
-->

<img src="./HCC2023-MDU.jpg" align="left" height="400" width="1024" >

<!-- <a href="url"><img src="./IMG_0898.jpg" align="left" height="48" width="48" opacity="0.5";></a> -->





<!--
# HCC2023

**Workshop on Human Centric Cybersecurity HCC2023**

**[Mälardalen University](https://www.mdu.se/en/malardalen-university), Västerås, Sweden**

**August 24th, 2023**
-->

## About
We are organizing the first workshop on human-centric cybersecurity at MDU. As in many other areas of engineering the term “human-centric” is becoming a mean to stress the importance of involving end-users and other stakeholders into the design processes, system development, and all the way to testing, validation and verification.
We have invited experts in the field from all over the world giving talks on various aspects of human-centric cybersecurity and safety, and in general human factor in our digital world.
The goal of the workshop is to use the knowledge and experience of the experts in the field and strengthen our knowledge on human-centric research.



## Invited Speakers
<!-- FIXME Check the links -->

**[Edward Lee](https://www2.eecs.berkeley.edu/Faculty/Homepages/lee.html), UC Berkeley, USA**

**[Hazem Torfah](https://www.chalmers.se/en/persons/hazemto/), Chalmers University of Technology, Sweden**

**[Marjan Sirjani](https://www.es.mdu.se/staff/3242-Marjan_Sirjani), Mälardalen University, Sweden** 

**[Matthias Wagner](https://portal.research.lu.se/sv/persons/matthias-wagner), Lund University, Sweden**

**[Shiva Sander Tavallaey](https://www.kth.se/profile/tssander), ABB and KTH, Sweden**

**[Claire Pagetti](https://www.onera.fr/en/staff/claire-pagetti), ONERA, France**

**[Pierluigi Nuzzo](https://www2.eecs.berkeley.edu/Faculty/Homepages/pnuzzo.html), UC Berkeley, USA**





## Invited Talks



## Edward A. Lee  
### Title: Certainty or Intelligence: Pick One!  

### Abstract  
Cyber-physical systems are systems that integrate software and networking with physical components that sense and actuate in the physical world. Traditionally, to make them trustworthy, engineers strive to make their behaviors predictable, repeatable, and provably safe. While security is essential to achieving these objectives, it is by no means sufficient. Many technical challenges arise with sporadic connectivity, real-time behaviors, and handling of inevitable faults.  

While the integration of machine-learning-based AI systems holds promise of being able to help deal with many of the security and other challenges, they simultaneously make behaviors less predictable and repeatable. In this talk, I postulate that the certainty that is traditionally achieved with rigorous engineering methods may be fundamentally incompatible with integrating intelligence into our systems. The question then becomes, how do we get the advantages of intelligence with acceptable risk?  

### Bio  
Edward A. Lee is Professor of the Graduate School and Distinguished Professor Emeritus in Electrical Engineering and Computer Sciences (EECS) at the University of California at Berkeley, where he has been on the faculty since 1986. He is the author of seven books, some with several editions, including two for a general audience, and hundreds of papers and technical reports.  

Lee has delivered more than 200 keynote and other invited talks at venues worldwide and has graduated 40 PhD students. His research group studies cyber-physical systems, which integrate physical dynamics with software and networks. His focus is on the use of deterministic models as a central part of the engineering toolkit for such systems. He is the director of iCyPhy, the Berkeley Industrial Cyber-Physical Systems Research Center.  

From 2005-2008, he served as Chair of the EE Division and then Chair of the EECS Department at UC Berkeley. He has led the development of several influential open-source software packages, notably Ptolemy and Lingua Franca.  

He received his BS degree in 1979 from Yale University, with a double major in Computer Science and Engineering and Applied Science, an SM degree in EECS from MIT in 1981, and a Ph.D. in EECS from UC Berkeley in 1986. From 1979 to 1982, he was a member of technical staff at Bell Labs in Holmdel, New Jersey, in the Advanced Data Communications Laboratory.  

He is a co-founder of BDTI, Inc., where he is currently a Senior Technical Advisor, and has consulted for a number of other companies. He is a Fellow of the IEEE, was an NSF Presidential Young Investigator, won the 1997 Frederick Emmons Terman Award for Engineering Education, received the 2016 Outstanding Technical Achievement and Leadership Award from the IEEE Technical Committee on Real-Time Systems (TCRTS), the 2018 Berkeley Citation, the 2019 IEEE Technical Committee on Cyber-Physical Systems (TCCPS) Technical Achievement Award, the 2022 European Design and Automation Association (EDAA) Achievement Award, the 2022 ACM SIGBED Technical Achievement Award, and an Honorary Doctorate in Computer Science from the Technical University of Vienna.  


## Hazem Torfah  
### Title: Learning and Monitoring the Operational Design Domain for AI-Based Autonomy  

### Abstract  
The deployment of autonomous systems in complex environments has increased significantly in recent years, with many relying on machine learning (ML) components for critical decision-making tasks. However, ML models are inherently brittle and prone to failures that can compromise system safety. This highlights the need for a systematic methodology to identify the conditions under which autonomy pipeline components may fail at design time and to detect such failures at runtime.  

This talk introduces a novel safety assurance approach for autonomous systems based on runtime verification. Runtime verification involves extracting information from a system at runtime and evaluating it to determine whether an execution satisfies or violates a given (safety) property. We will present recent advancements in runtime verification methods for capturing operational design domains (ODD), the conditions under which a system or its components are designed to operate safely. We will introduce a formalization for monitorable ODDs and discuss challenges in learning monitors for ODDs in noisy and unpredictable environments.  

### Bio  
*No bio provided.*  

## Marjan Sirjani  
### Title: Runtime monitoring and shielding AI-enabled CPS  

### Abstract  
*No abstract provided.*  

### Bio  
*No bio provided.*  


## Matthias Wagner  
### Title: The EU AI Act in Light of CPS: Assessing the Challenges and Impact of the Act’s Requirements on Industry

### Abstract  
The EU AI Act represents a significant legal framework with extraterritorial reach. This presentation will start with an overview of the AI Act and how it relates to CPS, followed by an in-depth analysis of its high-risk requirements from a software engineering perspective. Drawing on our recent study findings, we will identify the most challenging requirements as perceived by industry practitioners and elucidate the underlying reasons. Furthermore, we will assess the Act’s potential industry impacts, highlighting both positive and negative side effects.  

### Bio  
*No bio provided.*  


## Shiva Sander Tavallaey  
### Title: Trustworthy AI in Industrial Contexts: Balancing Innovation and Reliability  

### Abstract  
As artificial intelligence reshapes cyber-physical systems, the imperative for trustworthy AI has never been more critical. This talk explores the essential frameworks that enable responsible and effective AI deployment in industrial applications, with focus on technological robustness, ethical considerations, and operational reliability.  

The presentation will address three major dimensions of AI trustworthiness:  

- Strategic risk mitigation approaches that ensure predictability and safety in complex industrial settings  
- Ethical design principles emphasizing transparency and human-centric AI development  
- Technical methodologies for validating AI reliability  

By synthesizing theoretical insights with practical industrial applications, the talk will provide a proposal for developing AI technologies that are not just innovative, but also reliable and responsible.  

### Bio  
*No bio provided.*  


##  Claire Pagetti 
### Title: Formal verification and certified machine learning and Airbus    

### Abstract  
*No bio provided.*  

### Bio  
*No bio provided.*  

##  Pierluigi Nuzzo
### Title: Formal verification and AI in CPS  

### Abstract  
*No bio provided.*  

### Bio  
*No bio provided.*  

 
## Schedule

**09:00 - 10:00** &nbsp; &nbsp; **Edward Lee:** Certainty or Intelligence: Pick One!

**10:00 - 10:15** &nbsp; &nbsp; **Break**  

**10:15 - 11:00** &nbsp; &nbsp; **Hazem Torfah:** Formal verification and monitoring in autonomous driving  

**11:00 - 12:00** &nbsp; &nbsp; **Marjan Sirjani and team:** Runtime monitoring and shielding AI-enabled CPS  

**12:00 - 13:00** &nbsp; &nbsp; **Lunch Break***  

**13:00 - 13:40** &nbsp; &nbsp; **Matthias Wagner:** The EU AI Act in Light of CPS: Assessing the Challenges and Impact of the Act’s Requirements on Industry

**13:40 - 14:10** &nbsp; &nbsp; **Shiva Sander Tavallaey:** Trustworthy AI at ABB  

**14:10 - 15:00** &nbsp; &nbsp; **Panel**  

**15:00 - 15:15** &nbsp; &nbsp; **Break**  

**15:15 - 16:00** &nbsp; &nbsp; **Claire Pagetti (Online):** Formal verification and certified machine learning and Airbus  

**16:00 - 17:00** &nbsp; &nbsp; **Pierluigi Nuzzo (Online):** Formal verification and AI in CPS  



## Place

**Alpha** conference room, First floor of U building, MDU, Västerås. 

Please note that this is a hybrid event and you can also follow online, but a reliable connection is not guaranteed.

## Online
**Zoom:** TODO- put link

## Organizers
[Marjan Sirjani](http://www.es.mdu.se/staff/3242-Marjan_Sirjani)

TODO: any1 else?


## Contact Info
Marjan Sirjani

Email: marjan.sirjani@mdu.se

Room: U1-066C

Phone: +46736620517

